\section{Multithreading}

\begin{description}[itemsep=-1pt]
  \item[Moores Law] \textit{(An observation)} The number of transistors within the same area (=speed of computer) will double about every two years.   Physical (atomar) limits of this law have been reached already. New ways of speeding up processors are needed.
  
  \item[Hyperthreading] Two register sets to keep two separate contexts. If one task is busy, context switch can happen fast. Two logical from one physical core. Use wait time for more efficiency. 
  Performance increase is \emph{not} 100\% the amount of logical cores.
  
  \item[Parallel] Different processors act at the same time
  
  \item[Concurrent] Time-shared, one actor. Context switches needed.
  After the end of moores law: parallelization is needed for more speedup.
  
  \item[Process] One program instance. Separate address space, high isolation. Context switches are slow, communication overhead.
  
  \item[Thread] Parallel sequence within a program / process. Each has their own stack and registers, but all threads inside a process share the same heap. Changes made are seen by other threads inside the process, heap access must be synchronized.
  
  \item[Kernel thread] Implemented in kernel, context switch with interrupt. \textit{JVM default}.
  \item[User thread] no true parallelism, just concurrency.

  \item[Thread Scheduling / Processor Multiplexing] This is concurrency: Interleaved execution. 
  Each processor can execute one thread at a time. Multiple Threads are managed via scheduling mechanisms.
  States: Running, ready, waiting.
  Context switches are "lightweight" but still have a performance impact.

  \item[synchronous] (cooperative) waiting for condition, thread queues itself as waiting
  \item[asynchronous] (preemptive) resources are released after a set amount of time
  \item[Levels of parallelism] Hyperthreading, Multi-Core, Multi-Processor, Computing-Cluster.
\end{description}

\begin{minipage}[t]{0.5\linewidth}
\textbf{Interface Runnable}
\begin{lstlisting}[style=java]
class myLogic implements Runnable {
	@Override
	public void run() {
		// Thread Behavior
	}
}
var myThread = new Thread(new myLogic());
myThread.start();
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\textbf{Sub-Class of Thread}
\begin{lstlisting}[style=java]
class SimpleThread extends Thread {
	@Override
	public void run() {
		// Thread Behavior
	}
}
var myThread = new SimpleThread();
myThread.start();
\end{lstlisting}
\end{minipage}

\lstinline|Thread.sleep(ms)| warte und dann wieder ready \\
\lstinline|Thread.yield()| gibt CPU frei und ist direkt wieder ready -> Mehr Threadwechsel \\
\lstinline|t1.setDaemon(true)| JVM terminiert wenn alle Threads beendet mit Ausnahme von Deamons \\
\lstinline|Thread.currentThread()| gibt aktuellen Thread zurück \\
\lstinline|t1.join()| wartet, bis der Thread terminiert

\section{Synchronisationsprimitiven}
\textbf{Schutz von Shared Ressourcen}: Monitor, Semaphore, Lock\&Condition, RW-Lock \\
\textbf{Zeitlicher Synchronisation von mehreren Threads:} Latch, CyclicBarrier, Phase, Semaphore

\subsection{Monitor: Gegenseitiger Ausschluss + Wait\&Signal Mechanismus}
Jedes Objekt hat einen Monitor-Lock. Beziehen mittels synchronized-keyword. \lstinline|notify()/notifyAll()/wait()| nur in synchronized Block, ansonsten \lstinline|IllegalMOnitorStateException|.

\lstinline|wait()| 1. in inneren Warteraum gehen, 2. Monitor freigeben, 3. Inaktiv bis Wecksignal, 4. Monitor neu beziehen \\
\lstinline|notifyAll()| 1. Weckt alle Threads im Warteraum, 2. Behält das Monitor Lock (Keine FIFO Garantie)

\begin{minipage}[t]{0.75\linewidth}
\begin{lstlisting}[style=java]
class BankAccount {
	private int balance = 0;
	public synchronized void deposit(int amount) {
		balance += amount;
		notifyAll(); }
	public synchronized void withdraw(int amount) {
		while (balance < amount) { wait(); }
		balance -= amount; }
	public synchronized getBalance() {
		return balance; }
\end{lstlisting}	
\end{minipage}
\begin{minipage}[t]{0.25\linewidth}
	\textbf{Monitor auf Objekt} \\ \lstinline|synchronized(this)| \\
	\textbf{Monitor statische Methode} \\ \lstinline|synchronized(this.Class)|
	
\begin{lstlisting}[style=java]
public void method() {
	synchronized(this) {
		// code
	}
}
\end{lstlisting}
\end{minipage}

\textbf{Typische Fallen:} wait() mit if: Condition könnte durch schnelleren Thread validieren -> Überholproblem, Spurious Wakeup: wait() könnte auch ohne Signalisation returnen, es besagt nur, dass etwas geändert wurde, Single notify(): falls es unterschiedliche Wartebedingungen gibt, muss notifyAll verwendet werden.

\subsection{Semaphor: Vergabe eine beschränkter Anzahl freier Ressourcen, Objekt mit Zähler}
Die Semaphore ist im Vergleich zum Monitor schneller und konstanter, sowie Fairness-Flag vorhanden.

\lstinline|acquire()| Bezieht freie Ressource, Blockiert falls keine Verfügbar, \\
\lstinline|release()| Gibt eine Ressource wieder frei -> Inkrementiert Zähler, benachrichtigt wartende

\begin{lstlisting}[style=java]
class BoundedBuffer<T> {
	private Queue<T> queue = new LinkedList<>();
	private Semaphore upperLimit = new Semaphore(capacity, true);
	private Semaphore lowerLimit = new Semaphore(0, true);
	private Semaphore mutex = new Semaphore(1, true);
	public void put(T item) throws InterruptedException {
		upperLimit.acquire(); mutex.acquire(); queue.add(item); mutex.release(); lowerLimit.release(); }
	public T get() throws InterruptedException {
		lowerLimit.acquire(); mutex.acquire(); T item = queue.remove(); mutex.release(); upperLimit.release(); return item; }
\end{lstlisting}

\subsection{Lock \& Condition: Monitor mit mehreren Wartelisten für verschiedene Bedingungen}
\textbf{Äussere Warteliste:} Lock Objekt: Sperre für Eintritt in den Monitor \\
\textbf{Innere Warteliste:} Condition Objekt: Wait\&Signal für bestimmte Bedingung 

\begin{lstlisting}[style=java]
Class BoundedBuffer<T> {
   private Queue<T> queue = new LinkedList<>() ;
   private Lock monitor = new ReentrantLock(true); // fair
   private Condition nonFull  = monitor.newCondition() ;
   private Contition nonEmpty = monitor.newCondition() ;
   public void put(T item) throws InterruptedException { 
      monitor.lock() ; try {
         while(queue.size() == capacity) {nonFull.await() ; } queue.add(item) ; nonEmpty.signal() ;
      }  finally { monitor.unlock() ; } }
   public T get() throws InterruptedException {
      monitor.lock() ; try {
         while (queue.size() == 0) { nonEmpty.await() ; } T item = queue.remove() ; nonFull.signal() ; return item ;
      }  finally { monitory.unlock() ; }   }  }

\end{lstlisting}

\subsection{Read-Write Locks}
Write-Lock kann nicht bezogen werden, wenn bereits ein Read Lock bezogen ist.

\begin{lstlisting}[style=java]
class NameDatabase {
   private Collection<String> names = new HashSet<>() ;
   private ReadWriteLock rwLock = new ReentrantReadWriteLock(true) ; // fair
   public Collection<String> find(String pattern) { 
   rw.readLock().lock(); 
   try {
      for(String name : names) { if (name.matches(pattern) {return true ;} return false ; } // read only access
   } finally { rwLock.readLock().unlock() ; }
   public void put(String name) { 
   		rwLock.writeLock().lock() ; try  { names.add(name) ; // write access
   } finally {rwLock.writeLock().unlock() ; }  }  }	
\end{lstlisting}

\subsection{Count Down Latch (Eine bestimmte Anzahl Threads warten bis Counter <= 0)}
\lstinline|countDown()| Dekrementiert Zähler (Blockiert nie) \\
\lstinline|await()| Wartet bis der Zähler 0 ist und Blockiert 
Latches sind nur einmalig verwendbar (Er weiss nicht, wie viele Threads warten und kann somit den Latch nicht wieder schliessen)

\begin{lstlisting}[style=java]
CountDownLatch carsReady = new CountDownLatch(N);
carsReady.countDown(); carsReady.await();
\end{lstlisting}

\subsection{Cyclic Barrier (Warten auf eine fixe Anzahl Threads mit Wiederverwendung)}
\lstinline|await()| blockiert alle Parties auf der Barrier diese Funktion aufgerufen haben 

\begin{lstlisting}[style=java]
CyclicBarrier raceStart = new CyclicBarrier(N); 
raceStart.await();  raceStart.getParties(); 
\end{lstlisting}

\subsection{Exchanger (Genau zwei Teilnehmer (Rendez-Vous) blockiert bis ein anderer Thread exachange(x) aufruft.}
\begin{lstlisting}[style=java]
Exchanger<Integer> exchanger = new Exchanger<>() ; 
for (int k = 0 ; k<2 ; k++) { new Thread(() -> {for (int in = 0; in < 5; in++) {try {int out = exchanger.exchange(in) ; Sysout(Thread.currentThread().getName() + 'got' + out) ; } catch(InterruptedException ) {} }}}).start() ;}
\end{lstlisting}


\section{Gefahren der Nebenläufigkeit}
Es braucht keine Synchronisation, wenn Objekte unverändert (final), daher nur lesend zugegriffen werden oder wenn ein Objekt immer nur von einem Thread zur gleichen Zeit gehört (Confinement). 

\textbf{Thread-Confinement} Objekte nur über Referenzen von einem Thread erreichbar. \\
\textbf{Objekt-Confinement:} Objekt in anderen breites synchronisierten Objekt eingekapselt. \\
\textbf{Thread Safety:} 

\subsection{Race Conditions (Ungenügen synchronisierte Zugriff auf Shared Ressourcen)}
\textbf{Race Condition (Semantischer Fehler):} greifen mehrere Thread ohne genügende Synchronisation auf gemeinsame Ressourcen zu. Dies kann zu falschen Resultaten oder undefiniertem Verhalten führen. Diese Fehler hängen von der Thread-Verzahnung und der zeitlichen Ausführung ab.  \\
\textbf{Data Race (formaler Fehler):} Wenn zwei Threads auf die gleiche Speicheradresse zugreifen und mindestens ein Thread schreibt. Dabei ist der Zugriff ungenügend synchronisiert. (Data Race auf volatile Variablen ist nicht möglich, Race Conditions hingegen schon). 

\subsection{Deadlocks (Genseitiger Aussperren)}
Erkennung mit Betriebsmittelgraph (Zyklus im Graphen). Lösung : Lineare Sperrordnung der Ressourcen einführen oder Grobgranulare Locks. \textbf{Livelocks} blockieren sich permanent, verbrauchen aber noch CPU während der Warteinstruktion \\
\textbf{4 Bedingungen für Deadlock}: Geschachtelte Locks, Zyklische Warteabhängigkeiten, Gegenseitiger Ausschluss, Sperren ohne Timeout/Abbruch

\subsection{Starvation (Kontinuierliche Fortschrittsbehinderung wegen Fairness Problemen -> z.B. Monitor)}
Andere Threads überholen ständig, und schnappen einem Thread die Ressource weg. Folglich verhungert er. (abhängig von Scheduling). ACHTUNG : Bei Thread Prioritäten kann es zur Verdrängung kommen. Lösung: Faire Synchronisation.

\section{Thread Pools (Beschränkte Anzahl geteilte Worker Threads)}
Thread Pools haben den Vorteil, dass nicht unnötig viele Threads erzeugt werden. Einschränkung: Tasks dürfen nicht voneinander abhängig sein (Deadlock-Gefahr!). Nur der ForkJoinPool setzt Daemon Threads ein, alle anderen Pools müssen mit myPool.shutdown() beendet werden. Tasks werden mittels des Callable Interfaces implementiert.

\subsection{ForkJoinPool}
\lstinline|fork()| Starte als Sub-Task einen anderen Task \\
\lstinline|T join()| Warte auf das Task-Ende und frage das Resultat ab \\
\lstinline|T invoke()| Einen Sub-Task starte und synchron abwarten  \\
\lstinline|invokeAll(t1, t2)| Mehrere Sub-Tasks starten und abwarten

\begin{lstlisting}[style=java]
ForkJoinPool threadPool = new ForkJoinPool();
Future<Integer> future = threadPool.submit(() -> { // Future zukuenftiges Resultat
    int value = ...; // long calculation
    return value;  });
int result = future.get(); //get result from long calculation
threadPool.submit(() -> {  //Task Implementation  }); // Fire and Forget (DAEMON)!
\end{lstlisting}

\section{Asynchrone Programmierung}

\begin{lstlisting}[style=Java]
CompletableFuture<Long> fut = CompletableFuture.supplyAsny(() -> {
	longOp(); });
fut.ghenAccpet(res -> System.out.println(res);
\end{lstlisting}

\begin{lstlisting}[style=Java]
// Wait for all Futures
CompletableFuture.allOf(fut1, fut2).thenAccept(cont);
//Wait for ANY Future to arrive
CompletableFuture.any(fut1, fut2).thenAccept(cont);
\end{lstlisting}


\section{Memory Models (Lockfreie Datenstrukturen ermöglich effiziente Synchronisation, Compiler ordnet um)}
\textbf{Volatile:} Volatile verhindert Data Race auf Variable. Änderungen werden anderen Zugreifenden propagiert. Keine Umordnung durch Compiler. Atomares Lesen \& Schreiben auch für long und double \\
\textbf{Atomicity:} Zugriff auf Variable (Lesen/Schreibe) ist atomar für: primitive Datentypen bis 32 bit, Objektreferenzen, long und double nur mit volatile keyword. \\
\textbf{Visibility (Sichtbarkeit)} Sehen die Änderungen eines Threads eventuell gar nicht oder erst später, Optimierung, z.B. hält die VM Variablenwert in Register.

Die Sichtbarkeit ist garantiert bei:
\begin{itemize}
	\itemsep -0.2em
	\item Locks Release \& Acquire (Änderungen vor Release werden bei Acquire sichtbar)
	\item Volatile Variable (Zugriff macht Änderungen anderen Zugreifen sichtbar)
	\item Initialisierung von final Variablen (Nach Ende des Konstruktors)
	\item Thread-Start und Join (ebenso Task Start und Ende)
\end{itemize}

\textbf{Volatile Sichtbarkeit}: Alle Änderungen vor dem Zugriff auf die volatile Variable werden für alle Threads sichtbar, die danach auf diese volatile Variable zugreifen. Lese und Schreibzugriff invalidiert den Hauptspeicher (Memory Flush).

\subsection{.NET Memory Model (Unterschiede zu Java)}
\begin{itemize}
	\itemsep -0.2em
	\item Atomarität: long/double nicht mit volatile atomar
	\item Visibility: Nicht definiert. Implizit durch Ordering
	\item Ordering: volatile ist nur partielle fence
	\item Atomare Instruktionen mittels Interlocked Klasse
\end{itemize}

\subsection{Atomare Objekte (Kein Blockieren oder Warten auf Locks. Garantieren auch Ordering und Visibility)}

\begin{lstlisting}[style=java]
AtomicReference<Object>; AtomicInteger(); AtomicBoolean();
\end{lstlisting}

\lstinline|updateAndGet()| test
\lstinline|getAndUpdate()|
\lstinline|addAndGet(x)|
\lstinline|getAndAdd(x)|
\lstinline|compareAndSet(old, new)|

\textbf{Optimistische Synchronisation}
\begin{lstlisting}[style=java]
do {
	oldValue = var.get();
	newValue = calculateChanges(oldValue);
} while (!var.compareAndSet(oldValue, newValue);
\end{lstlisting}

\subsection{Lock-Free Data Structures}
Verwendet den CAS Algorithmus und verwendet keine Locks. \\
\lstinline|ConcurrentLinkedList<>();|
\lstinline|ConcurrentHashMap<K, V>();|

